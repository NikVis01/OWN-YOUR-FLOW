# OWN YOUR FLOW - C++ AI Agent
Created: 2025-08-03

```bash
                            .::..                                   .::.                            
            ...            .:-+*+:..                            ..:+*+-:.             ..            
           .-:..         .::+######=          ...::....        .=######+::.         ..:-            
              .:....  ...:-#######+.     .................     ..+#######-:.........:.              
              .=*+++-:-=**###*##*:......::--:..........:--::.... .:+##*###**+-:-+++*=.              
              .:+++====*#%%##%*:..:::......:::::-::-::::.......:::..:*%##%%%*+===+++:.              
               .:+=+*===+*%%@%##=:..........  ..:..::..........  .:=##%@%%*+===*+++:....            
                .-+++###+=+*=++:.. ....         ....         ...   .-++=*+=+###+++-.                
              .:.+#*+*##%*:++=:....:-...        ....        ...-:....:+++:*%##*+*#*.:               
              ..--#####%%::*-::=-=-:..::..      ....       .::..:-=-=:.-*-:%%#####--.               
                .:+###@#=::. ..=::.    ..-..   .:..:..  ..-..    .::=.  .::=#@###+:.                
              ..:+++**#%:::=--...::.    ...--::-*+++-::--...   ..::...--=:::%#**=++:.               
             .:=+--###%+=--:=+:. ..:..........::----::..........::. ..+=:--=+%##*--++:..            
            .++=:*#%%%%%#*==:=+=-......:. .+-::......::-*. .:......-=+=:==+#%%%%%#*:-++.            
          .-#*=*+=+%%#*+*##%*:+...::..  .:::-..       .-:::..  .::...=:*%##*+*#%%*=+*=**=.          
          .*==+*%#%%*#*++=*+#=-:.  .-.    .:.   ....   .:.     -.   .-=#**=++*%*%%#%*+==*.          
        ..=+===+*#%*#%%#*++*::-:   .::..       .=+*+.       ..::.   :=::**+*#%%#*%#*+===+=..        
      .:+=*#+++**#@####%%**:...-:......:-..     .::.      .::......:-....**%%####@#***++#*++:.      
    .-+**+**%*#%@@@@%##%##=--::-*@@@@@#+==-.......... ...:==+#@@@@@*-::--=*#%##%@@@@%#*%*****+=.    
    +*****+=*%@@%#%##%+=++*++#@@@@@@@@@@@@%+-:::-==-:::-+#@@@@@@@@@@@@#=**=+=+###%##@@%*=+*****+    
    .:=*=:....=**++##*#@@#=-=@@@@@@@@@@@@@@%%##+=--=+*#%%@@@@@@@@@@@@@@-=+#@@#**#++**=.....=*=:.    
           .-*++++=#%%#*@%+=:*@@@@@@%@@@@@@%#==.::-:.-=#%@@@@@@%@@@@@@*.==%@*#%%#=++++*-.           
           .=++**+++#%%%%+..:-*@@@@%%%%%@@%**:.:*%%*:.:*+%@@%%%%%@@@@*-:..=%#%%%+++**++=..          
           .-+%#****###+.....-**+======-:-:::.-%@@@@%-.:::-:-======+**-.....=####***#%+-.           
           ..:-*%**##%%----:::....::...:++#:.-%@@@@@@%=::#*+:...::....::::---%%#***%*-:.            
             .:.:*++-.:===%%-::::--::::.....:%@#@%#@#@%:.....::::--::::-%%===:.-+**:.:..            
                       .=##%#=+#%@@%*-==-.:::#%@****%%#:::.-==-*%@@%#++#%##+.                       
                        .=+###%@@@%#%#--:.. .-**++++**-. ..:-=#%#%@@@%###+=.                        
                         ..-****@@@%%#--:.. ..::%==%::.. ..:--#%%@@@***+-...                        
                          .-*+**%@@@@%+-:...:..............:-+%@@@@%**+*-.                          
                          .=+++**@@@@%+=+===--=-:..:----===+=+%@@@@**++*=.                          
                         .-+*++**+++#@%=-..:..=..--..=..:.:-=%@#*++**++#+-.                         
                          .+**+=+%=--=+:*+**:::..::..::.**+*:+=--=#+=+*++.                          
                           ..:++++##..=-=--:-.=+:==:+=.-:--=-=..*#+++*-..                           
                             ..-#**#:..-:=+==:-=----=-:==+=:-..:#**#=.                              
                                .=+=.. ..:+..-:..::..:-..+:..  .=+=:                                
                                 .:+=:..:..=.          .=..:..:=+:.                                 
                                    .=%*-...-..       .-...-*%=.                                    
                                     ...:---+..........+---:...                                     
                                         ..+-::=#%%#=-:-+..                                         
                   
```

There's recently been growing concerns of making API calls to model-providers considering data security, ownership, downtime and cost.

At the same time we've seen growth of agentic AI solutions in the tech market. 
The study “Small Language Models are the Future of Agentic AI”, Peter Belcak et al. (NVIDIA Research & Georgia Tech) advocates clearly for the use of smaller LLMs in agentic tasks.
This is a perfect setup for an agentic REST solution of an agent that I can deploy on my own wherever required in the future to perform RAG, web-search, sentiment analysis and more.
Link: https://arxiv.org/abs/2506.02153

Llama.cpp is perfect for this and to stick with the .cpp part I've chosen the C++ library Crow to deploy this project as a REST API.
Link: 

The CoT currently implemented is very rudimentary composed off 2 steps. Reason and generate (ReGe, if you will). 
With time I'll develop a more complex logical framework for the LLM to follow and execute tasks probably using instinct.cpp dubbed as "langchain.cpp" to manage tool-calling and tasks.
NOTE: This would require pivoting to llama-server as opposed to llama-run to execute prompts, since instinct.cpp does not support llama-run.
Link: 
https://github.com/RobinQu/instinct.cpp

Everything is currently implemented without Langchain, but instead done manually through program-flow. 

### Future:
As afformentioned this project will seek to build agentic capabilities manually through C++ program flow and langchain.cpp.
The goal is to minimize latency and cost of compute by writing in C++ and forcing the models to respond with low token counts.

## Build

```bash
mkdir build && cd build
cmake ..
make
```

## Run

```bash
./server
```

## API

POST `http://localhost:8000/data/`

```json
{
  "query": "your question"
}
```

## Dependencies

- yaml-cpp
- fmt
- llama.cpp (for llama-run binary)

## Llama.cpp Setup

```bash
# Clone llama.cpp
git clone https://github.com/ggerganov/llama.cpp.git

# Build with llama-run target
cd llama.cpp
mkdir build && cd build
cmake .. -DLLAMA_BUILD_SERVER=OFF -DLLAMA_BUILD_EXAMPLES=ON
make llama-run

# Download a model (example with TinyLlama, using Qwan in new version, you're welcome to experiment further)
mkdir models
wget https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v1.0-GGUF/resolve/main/tinyllama-1.1b-chat-v1.0.Q4_0.gguf -O models/tinyllama-1.1b-chat-v1.0.Q4_0.gguf
``` 

## Query (linux):

```bash
curl -X POST http://localhost:8000/data/      -H "Content-Type: application/json"      -d '{"query": "YOUR QUERY HERE"}'
```